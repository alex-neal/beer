?neuralnet
?glmnet
library(mxnet)
require(deepnet)
nn = nn.train(train_images, as.numeric(train$labels[1:100]), hidden=c(128))
?nn.predict
nn.predict(nn, train_images)
as.numeric(train$labels[1:100])
?nn.train
c(rep(1, 50), rep(0, 50))
install.packages("drat")
drat:::addRepo("dmlc")
install.packages("mxnet")
accuracy(nn)
load("~/Box Sync/utd_mscs/summer2020/datascience/Project2/.RData")
accuracy(nn)
require(magick)
require(tidyverse)
require(deepnet)
require(dummies)
accuracy(nn)
(51529*416)+416 + (416*672) + 672
(51529*416)+416 + (416*672) + 672 + (672*7)+7
(51529*256)+256 + (256*7)+7
load("~/Box Sync/utd_mscs/summer2020/datascience/Project2/.RData")
test_pred_prob
test_pred_prob[1,]
test$x[1,]
image(matrix(test$x[1,], nrow=227))
install.packages("tm")
library(tm)
getSources()
?getSources
getReaders()
URISource('http://www.google.com')
readPlain(URISource('https://www.google.com'))
readPlain(URISource('https://www.google.com'), language='english')
sup = readPlain(URISource('https://www.google.com'), language='english')
inspect(sup)
install.packages("recommenderlab")
vignette('recommendorlab')
vignette('recommenderlab')
recommenderRegistry$get_entry_names()
library(recommenderlab)
recommenderRegistry$get_entry_names()
?Recommender
m = matrix(c(1,NA,5,3,4,NA,3,5,3), byrow=TRUE, ncol=3)
m
rownames(m) = c('alice', 'bob', 'charlie')
m
colnames(m) = c('doctor strange', 'star trek: beyond', 'zootopia')
m
x = as(m, 'realratingMatrix')
x = as(m, 'realRatingMatrix')
x
?evaluationScheme
rec = Recommender(x, method='POPULAR')
rec
rec['bob']
m['bob']
m['bob',]
rec['bob',]
rec[1]
x
x['bob']
predict(rec, x['bob'])
?Recommender
pre = predict(rec, x['bob'])
pre
str(pre)
str(rec)
pre
str(pre)
m
m['charlie','zootopie'] = 2
m['charlie','zootopia'] = 2
m
x = as(m, 'realRatingsMatrix')
x = as(m, 'realRatingMatrix')
rec = Recommender(x, method='POPULAR')
pre = predict(rec, x['bob'])
pre
str(pre)
install.packages("arules")
install.packages("arules")
require(tidyverse)
require(arules)
url = 'https://ajndata.s3.us-east-2.amazonaws.com/instacart/'
# Import product info
products = read_csv(paste(url, 'products.csv', sep=''),
col_types=cols_only(product_id='i', product_name='c', department_id='i'))
products$product_name = gsub(',', '', products$product_name)  # remove commas to avoid confusion in itemsets
# Import department info
departments = read_csv(paste(url, 'departments.csv', sep=''),
col_types=cols_only(department_id='i', department='c'))
# Import orders
# Combine 'prior' and 'train' to get full dataset for this task
orders1 = read_csv(paste(url, 'order_products__prior.csv', sep=''),
col_types=cols_only(order_id='i', product_id='i'))
orders2 = read_csv(paste(url, 'order_products__train.csv', sep=''),
col_types=cols_only(order_id='i', product_id='i'))
orders = rbind(orders1, orders2)
# Join orders with product and department info
df = left_join(orders, products) %>% left_join(departments) %>% select(-product_id, -department_id)
df
rm(products, departments, orders, orders1, orders2) # Initial dataframes no longer needed
# Create transactions for using products
write.table(df, file = tmp <- file(), row.names = FALSE)
product_tr <- read.transactions(tmp, format = "single", header=TRUE,
skip=-1, cols = c("order_id", "product_name"))
close(tmp)
# Create transactions using departments
write.table(df, file = tmp <- file(), row.names = FALSE)
department_tr <- read.transactions(tmp, format = "single",
header = TRUE, skip=-1, cols = c("order_id", "department"),
rm.duplicates=TRUE)
close(tmp)
freq_to_csv = function(freq, filename, max_rows) {
out = as_tibble(as(freq, 'data.frame')) %>% select(-transIdenticalToItemsets)
if (nrow(out) > max_rows) {
out = out[1:max_rows,]
}
out$items = gsub(',', ', ', out$items)
out$support = round(out$support, 4)
write_csv(out, filename)
}
# View frequency plot
itemFrequencyPlot(product_tr, topN=15, type='absolute', main='Frequent Products')
product_freq = eclat(product_tr, parameter=list(support=0.01, minlen=2)) %>%
sort(by='support', decreasing=TRUE)
inspect(product_freq)
department_rules_snacks = apriori(department_tr, parameter = list(supp = 0.05, conf = 0.6),
appearance=list(default='lhs', rhs='snacks')) %>%
sort(by='confidence', decreasing=TRUE)
inspect(department_rules_snacks)
install.packages(c("quantmod", "tidyquant"))
library(quantmod)
library(tidyquant)
?getSymbols
?getSymbols
getSymbols('TARG')
getSymbols('GOOG')
chartSeries(GOOG)
add_SMA(n=50)
add_SMA()
?add_SMA
head(GOOG)
add_SMA(n=50, with.col='GOOG.Close')
add_SMA(n=50)
chartSeries(GOOG, subset='2010')
add_SMA(n=50)
?Cl
Cl(GOOG)
head(Cl(GOOG))
add_SMA()
add_EMA()
add_SMA
?add_SMA
?TTR
# Required Libraries
require(tidyquant)
require(reshape2)
# Download 30 years of daily SPY data
spy = tq_get('SPY', from='1990-01-01')
# Calculate SMA and remove early datapoints where SMA is not available
spy = spy %>% tq_mutate(select=adjusted, mutate_fun=SMA, n=200) %>% filter(!is.na(SMA))
# Plot monthly adjusted close prices and SMA
spy %>% tq_transmute(mutate_fun=to.period, period='months') %>%
ggplot() +
geom_line(aes(x=date, y=adjusted)) + geom_line(aes(x=date, y=SMA), col='red') +
labs(title='SPDR S&P 500 (SPY), Nov 1993 - Jul 2020',
subtitle='Red line shows 200 day simple moving average',
x='', y='Share Price (USD)') +
theme_tq()
# Get daily value of assets following strategy 1
backtest_strat1 = function(data) {
num_shares = 0    # Number of shares of SPY owned
cur_month = as.yearmon(min(data$date)) - 1  # Keep track of the current month
values = NULL   # Vector of daily values (num_shares * adjusted_close_price)
for (i in 1:nrow(data)) {
row = data[i,]
# On first day of the month, invest 1000 more dollars
if (cur_month < as.yearmon(row$date)) {
num_shares = num_shares + (1000 / row$adjusted)
cur_month = as.yearmon(row$date)
}
# Calculate and store value for the day
values = c(values, (num_shares*row$adjusted))
}
return(tibble(date=data$date, strategy='1', value=values))
}
# Get daily value of assets following strategy 2
backtest_strat2 = function(data) {
savings = 0     # Amount of USD in savings account
num_shares = 0    # Number of shares of SPY owned
cur_month = as.yearmon(min(data$date)) - 1   # Keep track of current month
values = NULL   # Vector of daily values (num_shares * adjusted_close_price)
for (i in 1:nrow(data)) {
row = data[i,]
# On first day of month, add 1000 to savings account
if (cur_month < as.yearmon(row$date)) {
savings = savings + 1000
cur_month = as.yearmon(row$date)
}
# Invest all money if: savings is non-empty and there is a buy signal
# Move to savings account if: shares are owned and there is a sell signal
if (row$adjusted > row$SMA & savings > 0) {
num_shares = num_shares + (savings / row$adjusted)
savings = 0
} else if (row$adjusted <= row$SMA & num_shares > 0) {
savings = savings + (num_shares * row$adjusted)
num_shares = 0
}
# Store value for the day
values = c(values, savings + (num_shares*row$adjusted))
}
return(tibble(date=data$date, strategy='2', value=values))
}
# Perform the two backtests and combine results into a tibble
results = bind_rows(backtest_strat1(spy), backtest_strat2(spy)) %>% group_by(strategy)
# Required Libraries
require(tidyverse)
require(tidyquant)
require(reshape2)
# Download 30 years of daily SPY data
spy = tq_get('SPY', from='1990-01-01')
# Calculate SMA and remove early datapoints where SMA is not available
spy = spy %>% tq_mutate(select=adjusted, mutate_fun=SMA, n=200) %>% filter(!is.na(SMA))
# Plot monthly adjusted close prices and SMA
spy %>% tq_transmute(mutate_fun=to.period, period='months') %>%
ggplot() +
geom_line(aes(x=date, y=adjusted)) + geom_line(aes(x=date, y=SMA), col='red') +
labs(title='SPDR S&P 500 (SPY), Nov 1993 - Jul 2020',
subtitle='Red line shows 200 day simple moving average',
x='', y='Share Price (USD)') +
theme_tq()
# Get daily value of assets following strategy 1
backtest_strat1 = function(data) {
num_shares = 0    # Number of shares of SPY owned
cur_month = as.yearmon(min(data$date)) - 1  # Keep track of the current month
values = NULL   # Vector of daily values (num_shares * adjusted_close_price)
for (i in 1:nrow(data)) {
row = data[i,]
# On first day of the month, invest 1000 more dollars
if (cur_month < as.yearmon(row$date)) {
num_shares = num_shares + (1000 / row$adjusted)
cur_month = as.yearmon(row$date)
}
# Calculate and store value for the day
values = c(values, (num_shares*row$adjusted))
}
return(tibble(date=data$date, strategy='1', value=values))
}
# Get daily value of assets following strategy 2
backtest_strat2 = function(data) {
savings = 0     # Amount of USD in savings account
num_shares = 0    # Number of shares of SPY owned
cur_month = as.yearmon(min(data$date)) - 1   # Keep track of current month
values = NULL   # Vector of daily values (num_shares * adjusted_close_price)
for (i in 1:nrow(data)) {
row = data[i,]
# On first day of month, add 1000 to savings account
if (cur_month < as.yearmon(row$date)) {
savings = savings + 1000
cur_month = as.yearmon(row$date)
}
# Invest all money if: savings is non-empty and there is a buy signal
# Move to savings account if: shares are owned and there is a sell signal
if (row$adjusted > row$SMA & savings > 0) {
num_shares = num_shares + (savings / row$adjusted)
savings = 0
} else if (row$adjusted <= row$SMA & num_shares > 0) {
savings = savings + (num_shares * row$adjusted)
num_shares = 0
}
# Store value for the day
values = c(values, savings + (num_shares*row$adjusted))
}
return(tibble(date=data$date, strategy='2', value=values))
}
# Perform the two backtests and combine results into a tibble
results = bind_rows(backtest_strat1(spy), backtest_strat2(spy)) %>% group_by(strategy)
# Use monthly periodicity for smoother visualization
value_monthly = results %>%
tq_transmute(select=value, mutate_fun=to.period, period='months')
value_monthly
642/27
642/2
321/27
321*1000
(1258222.23-321000)/321000
321000*2.91
934110+321000
321000*2.92
937320+321000
(873521.99-321000)/321000
?ts
setwd("~/Box Sync/utd_mscs/jobs/Loopback Assignment")
require(tidyverse)
df = read_csv('beer_reviews.csv')
df
numeric_columns = select_if(df, is.numeric)
M = cor(numeric_columns)
corrplot(M)
require(corrplot)
corrplot(M)
numeric_columns = select(df, c('review_overall', 'review_aroma', 'review_appearance', 'review_palate', 'review_taste'))
M = cor(numeric_columns)
corrplot(M)
df % group_by('brewery_name') % summarize(mean_abv=mean('beer_abv'))
df %>% group_by('brewery_name') %>% summarize(mean_abv=mean('beer_abv'))
?mean
df %>% group_by('brewery_name') %>% summarize(mean_abv=mean('beer_abv', na.rm=TRUE))
df %>% group_by(brewery_name) %>% summarize(mean_abv=mean(beer_abv, na.rm=TRUE))
df %>% group_by(brewery_name) %>% summarize(mean_abv=mean(beer_abv, na.rm=TRUE)) %>% sort()
df %>% group_by(brewery_name) %>% summarize(mean_abv=mean(beer_abv, na.rm=TRUE)) %>% sort()
df %>% group_by(brewery_name) %>% summarize(mean_abv=mean(beer_abv, na.rm=TRUE)) %>% arrange()
df %>% group_by(brewery_name) %>% summarize(mean_abv=mean(beer_abv, na.rm=TRUE)) %>% arrange(mean_abv)
?arrange
df %>% group_by(brewery_name) %>% summarize(mean_abv=mean(beer_abv, na.rm=TRUE)) %>% arrange(desc(mean_abv))
df
df %>% group_by(brewery_name, beer_name) %>% summarize(abv=mean(beer_abv, na.rm=TRUE))
df %>% group_by(brewery_name, beer_name) %>% summarize(abv=mean(beer_abv, na.rm=TRUE)) %>% group_by(brewery_name) %>% summarize(mean_abv=mean(abv,na.rm=TRUE))
df %>% group_by(brewery_name, beer_name) %>% summarize(abv=mean(beer_abv, na.rm=TRUE)) %>% group_by(brewery_name) %>% summarize(mean_abv=mean(abv,na.rm=TRUE)) %>% arrange(desc(mean_abv))
df %>% group_by(brewery_name, beer_name) %>% summarize(abv=mean(beer_abv, na.rm=TRUE)) %>% group_by(brewery_name) %>% summarize(mean_abv=mean(abv,na.rm=TRUE), beer_count=n()) %>% arrange(desc(mean_abv))
#  If you had to pick 3 beers to recommend using only this data, which would you pick?
df %>% group_by(brewery_name, beer_name) %>%
summarize(mean_overall=mean(review_overall)) %>% review_count=n()) %>%
arrange(desc(mean_overrall))
#  If you had to pick 3 beers to recommend using only this data, which would you pick?
df %>% group_by(brewery_name, beer_name) %>%
summarize(mean_overall=mean(review_overall)) %>% review_count=n()) %>%
arrange(desc(mean_overall))
#  If you had to pick 3 beers to recommend using only this data, which would you pick?
df %>% group_by(brewery_name, beer_name) %>%
summarize(mean_overall=mean(review_overall), review_count=n()) %>%
arrange(desc(mean_overall))
summary(df$review_overall
)
#  If you had to pick 3 beers to recommend using only this data, which would you pick?
beers = df %>% group_by(brewery_name, beer_name) %>%
summarize(mean_overall=mean(review_overall), review_count=n()) %>%
arrange(desc(mean_overall))
beers
summary(beers$review_count)
ggplot(beers) + geom_histogram(aes(x=review_count))
beers = beers %>% filter(review_count > 24)
beers
beers2 = beers %>% filter(review_count > 1000)
#  If you had to pick 3 beers to recommend using only this data, which would you pick?
beers = df %>% group_by(brewery_name, beer_name) %>%
summarize(mean_overall=mean(review_overall), review_count=n()) %>%
arrange(desc(mean_overall))
ggplot(beers) + geom_histogram(aes(x=review_count))
beers2 = beers %>% filter(review_count > 1000)
beers2
beers
#  If you had to pick 3 beers to recommend using only this data, which would you pick?
beers = df %>% group_by(brewery_name, beer_name) %>%
summarize(mean_overall=mean(review_overall), sd_overall=sd(review_overall), review_count=n()) %>%
arrange(desc(mean_overall))
beers
sd(1)
sd(c(1,2))
beers %>% mutate(ci_low=mean_overall-1.96*sd_overall/sqrt(review_count))
beers %>% mutate(ci=mean_overall+c(-1,1)*1.96*sd_overall/sqrt(review_count))
beers %>% mutate(ci_low=mean_overall-1.96*sd_overall/sqrt(review_count))
beers %>% mutate(ci_low=mean_overall-1.96*sd_overall/sqrt(review_count), ci_high=mean_overall+1.96*sd_overall/sqrt(review_count))
beers %>% mutate(ci_low=mean_overall-1.96*sd_overall/sqrt(review_count), ci_high=mean_overall+1.96*sd_overall/sqrt(review_count)) %>% filter(review_count > 1)
sd(c(4,4))
beers %>% mutate(ci_low=mean_overall-1.96*sd_overall/sqrt(review_count), ci_high=mean_overall+1.96*sd_overall/sqrt(review_count)) %>% filter(review_count > 30)
#  Which brewery produces the strongest beers by ABV
df %>% group_by(brewery_name, beer_name) %>%
summarize(abv=mean(beer_abv, na.rm=TRUE)) %>%
group_by(brewery_name) %>%
summarize(mean_abv=mean(abv,na.rm=TRUE), beer_count=n()) %>%
arrange(desc(mean_abv))
df %>% filter(brewery_name=="Morgan Street Brewery") %>% select(brewery_name, beer_abv)
df %>% filter(brewery_name=="Morgan Street Brewery") %>% select(brewery_name, beery_name, beer_abv)
df %>% filter(brewery_name=="Morgan Street Brewery") %>% select(brewery_name, beer_name, beer_abv)
#  Which brewery produces the strongest beers by ABV
df %>% drop_na(beer_abv) %>%
group_by(brewery_name, beer_name) %>%
summarize(abv=mean(beer_abv)) %>%
group_by(brewery_name) %>%
summarize(mean_abv=mean(abv), beer_count=n()) %>%
arrange(desc(mean_abv))
df %>% filter(brewery_name=="Snowy Mountain Brewery")
df %>% filter(brewery_name=="Snowy Mountain Brewery") %>% select(beer_abv)
#  Which brewery produces the strongest beers by ABV
df %>% drop_na(beer_abv) %>%
group_by(brewery_name, beer_name) %>%
summarize(abv=mean(beer_abv)) %>%
group_by(brewery_name) %>%
summarize(mean_abv=mean(abv), beer_count=n()) %>%
arrange(desc(mean_abv))
df %>% filter(brewery_name="Schorschbräu")
df %>% filter(brewery_name=="Schorschbräu")
df %>% filter(brewery_name=="Schorschbräu") %>% select(beer_abv)
df %>% filter(brewery_name=="Schorschbräu") %>% group_by(beer_name) %>% summarize(mean_abv=mean(beer_abv))
#  If you had to pick 3 beers to recommend using only this data, which would you pick?
beers = df %>% group_by(brewery_name, beer_name) %>%
summarize(mean_overall=mean(review_overall), sd_overall=sd(review_overall), review_count=n()) %>%
arrange(desc(mean_overall))
ggplot(beers) + geom_histogram(aes(x=review_count))
beers2 = beers %>% filter(review_count > 30)
beers2
ggplot(df) + geom_histogram(aes(x=beer_abv))
# Which of the factors (aroma, taste, appearance, palette) are most important in determining the overall quality of a beer?
reviews = select(df, c('review_overall', 'review_aroma', 'review_appearance', 'review_palate', 'review_taste'))
M = cor(reviews)
corrplot(M)
lm(review_overall ~ ., data=reviews)
model = lm(review_overall ~ ., data=reviews)
summary(model)
?corrplot
df
df %>% select(beer_style)
df %>% distinct(beer_style)
# If I typically enjoy a beer due to its aroma and appearance, which beer style should I try?
df %>% group_by(beer_style) %>%
summarize(count=n(), mean_aroma=mean(review_aroma), mean_appearance=mean(review_appearance))
# If I typically enjoy a beer due to its aroma and appearance, which beer style should I try?
df %>% group_by(beer_style) %>%
summarize(count=n(), mean_aroma=mean(review_aroma), mean_appearance=mean(review_appearance)) %>%
mutate(composite_score=(mean_aroma+mean_appearance)/2)
# If I typically enjoy a beer due to its aroma and appearance, which beer style should I try?
df %>% group_by(beer_style) %>%
summarize(count=n(), mean_aroma=mean(review_aroma), mean_appearance=mean(review_appearance)) %>%
mutate(composite_score=(mean_aroma+mean_appearance)/2) %>%
arrange(desc(composite_score))
# If I typically enjoy a beer due to its aroma and appearance, which beer style should I try?
a = df %>% group_by(beer_style) %>%
summarize(count=n(), mean_aroma=mean(review_aroma), mean_appearance=mean(review_appearance)) %>%
mutate(composite_score=(mean_aroma+mean_appearance)/2) %>%
arrange(desc(composite_score))
view(a)
#  Which brewery produces the strongest beers by ABV
df %>% drop_na(beer_abv) %>%
group_by(brewery_name, beer_name) %>%
summarize(abv=mean(beer_abv)) %>%
group_by(brewery_name) %>%
summarize(mean_abv=mean(abv), beer_count=n()) %>%
arrange(desc(mean_abv))
#  Which brewery produces the strongest beers by ABV
strongest = df %>%
drop_na(beer_abv) %>%
group_by(brewery_name, beer_name) %>%
summarize(abv=mean(beer_abv)) %>%
group_by(brewery_name) %>%
summarize(mean_abv=mean(abv), beer_count=n()) %>%
arrange(desc(mean_abv))
strongest
?top_n
#  Which brewery produces the strongest beers by ABV
strongest = df %>%
drop_na(beer_abv) %>%
group_by(brewery_name, beer_name) %>%
summarize(abv=mean(beer_abv)) %>%
group_by(brewery_name) %>%
summarize(mean_abv=mean(abv), beer_count=n()) %>%
slice_max(mean_abv), 10)
#  Which brewery produces the strongest beers by ABV
strongest = df %>%
drop_na(beer_abv) %>%
group_by(brewery_name, beer_name) %>%
summarize(abv=mean(beer_abv)) %>%
group_by(brewery_name) %>%
summarize(mean_abv=mean(abv), beer_count=n()) %>%
slice_max(mean_abv, 10)
strongest
#  Which brewery produces the strongest beers by ABV
strongest = df %>%
drop_na(beer_abv) %>%
group_by(brewery_name, beer_name) %>%
summarize(abv=mean(beer_abv)) %>%
group_by(brewery_name) %>%
summarize(mean_abv=mean(abv), beer_count=n()) %>%
slice_max(mean_abv, n=10)
strongest
#  Which brewery produces the strongest beers by ABV
strongest = df %>%
drop_na(beer_abv) %>%
group_by(brewery_name, beer_name) %>%
summarize(abv=mean(beer_abv)) %>%
group_by(brewery_name) %>%
summarize(mean_abv=mean(abv), beer_count=n()) %>%
slice_max(mean_abv, n=9)
strongest
#  Which brewery produces the strongest beers by ABV
strongest = df %>%
drop_na(beer_abv) %>%
group_by(brewery_name, beer_name) %>%
summarize(abv=mean(beer_abv)) %>%
group_by(brewery_name) %>%
summarize(mean_abv=mean(abv), beer_count=n()) %>%
slice_max(mean_abv, n=7)
strongest
ggplot(strongest) + geom_bar(aes(x=brewery_name, y=mean_abv))
ggplot(strongest) + geom_col(aes(x=brewery_name, y=mean_abv))
#  Which brewery produces the strongest beers by ABV
strongest = df %>%
drop_na(beer_abv) %>%
group_by(brewery_name, beer_name) %>%
summarize(abv=mean(beer_abv)) %>%
group_by(brewery_name) %>%
summarize(mean_abv=mean(abv), beer_count=n()) %>%
arrange(desc(mean_abv))
ggplot(strongest) + geom_col(aes(x=brewery_name, y=mean_abv))
?head
strongest %>% head(5)
?geom_col
